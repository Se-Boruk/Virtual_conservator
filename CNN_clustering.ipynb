{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# The dataset class can have the exact same code as before, no changes needed.\n",
        "\n",
        "# Combined Waste Dataset for Multiclass Classification\n",
        "# Uses CSV splits generated by create_dataset_splits.py\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the classes (same as in the combination script)\n",
        "final_classes = {\n",
        "    'organic': 0,\n",
        "    'battery': 1,\n",
        "    'glass': 2,\n",
        "    'metal': 3,\n",
        "    'paper': 4,\n",
        "    'cardboard': 5,\n",
        "    'plastic': 6,\n",
        "    'textiles': 7,\n",
        "    'trash': 8,\n",
        "}\n",
        "\n",
        "class CombinedWasteDatasetMulti(Dataset):\n",
        "    def __init__(self, root_dir=\"./datasets/combined_waste_dataset\",\n",
        "                 split='train', transform=None):\n",
        "        \"\"\"\n",
        "        Multiclass waste dataset using CSV splits.\n",
        "\n",
        "        Args:\n",
        "            root_dir (str): Path to the combined waste dataset directory.\n",
        "            split (str): 'train', 'val', or 'test'.\n",
        "            transform: Transformations to apply to images.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.classes = list(final_classes.keys())\n",
        "        self.class_to_idx = final_classes\n",
        "        self.data = []\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        csv_path = os.path.join(self.root_dir, f'{self.split}.csv')\n",
        "        if not os.path.exists(csv_path):\n",
        "            raise FileNotFoundError(f\"CSV file {csv_path} not found. \"\n",
        "                                    \"Run create_dataset_splits.py first.\")\n",
        "\n",
        "        df = pd.read_csv(csv_path)\n",
        "        for _, row in df.iterrows():\n",
        "            img_path = os.path.join(self.root_dir, row['image_path'])\n",
        "            label = self.class_to_idx[row['class']]\n",
        "            self.data.append((img_path, label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "T-jOhRGEr-es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Counter\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset_root = './datasets/combined_waste_dataset'\n",
        "\n",
        "for split in ['train', 'val', 'test']:\n",
        "    dataset = CombinedWasteDatasetMulti(\n",
        "        root_dir=dataset_root, split=split, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "    print(f\"Split: {split}, Total Samples: {len(dataset)}\")\n",
        "\n",
        "    # Count images per class\n",
        "    labels = [label for _, label in dataset.data]\n",
        "    counts = Counter(labels)\n",
        "    print(\"  Class distribution:\")\n",
        "    for cls_idx in sorted(counts.keys()):\n",
        "        cls_name = dataset.classes[cls_idx]\n",
        "        print(f\"    {cls_name} ({cls_idx}): {counts[cls_idx]} images\")\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        # Test one batch\n",
        "        for images, labels_batch in dataloader:\n",
        "            print(f\"  Batch shape: {images.shape}, Labels: {labels_batch[0:5] } (...)\")\n",
        "            break"
      ],
      "metadata": {
        "id": "kRPFZ_VNsBMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, now we can think about the architecture of our model.\n",
        "Our first attempt was an architecture \"inspired\" by VGG network.\n",
        "\n",
        "But it was neither a direct copy nor something based on gained knowledge. It was more of a guess.\n",
        "How would we know we picked a good architecture?\n",
        "\n",
        "We can see from literature, that Architecutures are usualy designed through a combination of:\n",
        "- Empirical testing\n",
        "- Prior knowledge\n",
        "- Automated search (Neural Architecture Search - NAS)\n",
        "\n",
        "Let's try do do something similiar here.\n",
        "We can try to implement our network in a modular way, so that we can easily change its architecture.\n",
        "\n",
        "We can define building blocks for our network, such as convolutional layers, activation functions, and pooling layers, and then compose them to create the final architecture.\n",
        "\n",
        "This way, we can easily experiment with different configurations and find the best-performing architecture for our task.\n",
        "\n",
        "For now let's stick to things that are \"inspired\" by literature. We know what worked previously AND was simple:\n",
        "- AlexNet\n",
        "- VGG\n",
        "\n",
        "Let's try to implement modular versions of these architectures and see how they perform on our dataset.\n",
        "Knowing how to build modular architectures is a useful skill, as basically anything more complicated will be just a combination of simpler blocks.\n",
        "So all future architectures you will encounter will be created like this.\n",
        "\n",
        "\n",
        "\n",
        "The source of VGG architecture:\n",
        "https://arxiv.org/pdf/1409.1556\n",
        "\n",
        "We will get inspirations from it, BUT it has no drawing of the architecture itself.\n",
        "Fortunately there are multiple articles that describe it in more detail, e.g.:\n",
        "https://neurohive.io/en/popular-networks/vgg16/\n",
        "https://lekhuyen.medium.com/an-overview-of-vgg16-and-nin-models-96e4bf398484\n",
        "\n",
        "AND many other articles, like:\n",
        "https://www.researchgate.net/figure/GG-16-network-architecture-for-feature-extraction_fig1_335184836\n",
        "\n",
        "(These are just exaples, to visualize the architecture)\n",
        "\n"
      ],
      "metadata": {
        "id": "NDjGQWTksFPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
        "from torchsummary import summary\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "\n",
        "# Set seed for reproducibility\n",
        "pl.seed_everything(42)\n"
      ],
      "metadata": {
        "id": "-yg6GtgAsGd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentations for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
        "])\n",
        "\n",
        "# Validation and test transforms\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "VWVtirMvsIXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WasteDataModuleMulti(LightningDataModule):\n",
        "    def __init__(self, root_dir='datasets/combined_waste_dataset',\n",
        "                 batch_size=32):\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = 9  # organic, battery, glass, metal, paper, cardboard, plastic, textiles, trash\n",
        "        self.class_weights = None\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = CombinedWasteDatasetMulti(\n",
        "            root_dir=self.root_dir, split='train', transform=train_transform\n",
        "        )\n",
        "        self.val_dataset = CombinedWasteDatasetMulti(\n",
        "            root_dir=self.root_dir, split='val', transform=val_test_transform\n",
        "        )\n",
        "        self.test_dataset = CombinedWasteDatasetMulti(\n",
        "            root_dir=self.root_dir, split='test', transform=val_test_transform\n",
        "        )\n",
        "\n",
        "        self.num_workers = os.cpu_count() - 1\n",
        "\n",
        "        # Compute sample weights for weighted random sampling\n",
        "        # Now why would we do that?\n",
        "        # In imbalanced datasets, some classes may be underrepresented in the training data.\n",
        "        # By assigning higher weights to these classes, we can ensure that the model pays more attention to them during training.\n",
        "        # This can help improve the model's performance on minority classes and lead to a more balanced overall performance.\n",
        "\n",
        "        # In \"statistical\" terms we are trying to reduce the variance of our estimator by ensuring that all classes are adequately represented in each batch.\n",
        "        # In Easy english - because our dataset is imbalanced, we want to make sure that during training, the model sees enough examples from all classes.\n",
        "        # otherwise the probability of batches without any samples from minority classes is high, and the model will not learn to recognize them well.\n",
        "\n",
        "        # This approach Creates class-balanced batches for the model to train on,\n",
        "        # which changes the actual data distribution seen by the model during training.\n",
        "\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            self.sample_weights = [self.class_weights[label].item() for _, label in self.train_dataset.data]\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        if hasattr(self, 'sample_weights'):\n",
        "            # Create a weighted random sampler for stratified sampling\n",
        "            # replacement = True to allow sampling with replacement\n",
        "            # as usual - more info in the docs:\n",
        "            # https://docs.pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler\n",
        "            # if replacement = False -> without replacement - when a sample index is drawn for a row, it cannot be drawn again for that row\n",
        "            sampler = WeightedRandomSampler(self.sample_weights, len(self.train_dataset), replacement=True)\n",
        "\n",
        "            return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
        "                              sampler=sampler, num_workers=self.num_workers)\n",
        "        else:\n",
        "            return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
        "                              shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=False, num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=False, num_workers=self.num_workers)"
      ],
      "metadata": {
        "id": "7iiPWEtrsIZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParametricCNN(LightningModule):\n",
        "    def __init__(self, num_classes=9, class_weights=None, architecture_config=None):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Default architecture config (our first, \"VGG-like\")\n",
        "        if architecture_config is None:\n",
        "            architecture_config = {\n",
        "                'blocks': [\n",
        "                    {'filters': 64, 'convs': 2},\n",
        "                    {'filters': 128, 'convs': 2},\n",
        "                    {'filters': 256, 'convs': 2},\n",
        "                ],\n",
        "                'dropout_conv': 0.25,\n",
        "                'fc_units': 512,\n",
        "                'dropout_fc': 0.5\n",
        "            }\n",
        "\n",
        "        self.architecture_config = architecture_config\n",
        "\n",
        "        # we can start building the model now\n",
        "        # this is not the most elegant way to do it, but it is straightforward and clear\n",
        "        # this is also not super flexible, it does not allow us to build any possible architecture,\n",
        "        # but it is not supposed to\n",
        "\n",
        "        # almost every architecture you will see will work like that\n",
        "        # just a lot of them will be more complex (ResNet, DenseNet, etc.)\n",
        "        # however, the basic idea is still the same - we have a configurtion that defines the architecture\n",
        "        # and we build the model based on that configuration, using simple \"factory\" pattern,\n",
        "        # creating our network from blocks, defined in the configuration\n",
        "        # this is especially true when creating a Sequential / linear stack of layers\n",
        "\n",
        "\n",
        "        # Build convolutional layers\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for block in architecture_config['blocks']:\n",
        "            for _ in range(block['convs']):\n",
        "                layers.append(nn.Conv2d(in_channels, block['filters'], kernel_size=3, padding=1))\n",
        "                layers.append(nn.BatchNorm2d(block['filters']))\n",
        "                layers.append(nn.ReLU())\n",
        "                in_channels = block['filters']\n",
        "            layers.append(nn.MaxPool2d(2, 2))\n",
        "            layers.append(nn.Dropout(architecture_config['dropout_conv']))\n",
        "\n",
        "        layers.append(nn.Flatten())\n",
        "\n",
        "        # Compute the flatten size dynamically\n",
        "        # otherwise we would have to hardcode it, which would be almost impossible to do\n",
        "\n",
        "        # let's use a trick - \"run\" the model we have so far on a dummy input\n",
        "        # we just have to be careful to not track gradients here\n",
        "        # that is why we use torch.inference_mode()\n",
        "        # TODO: what is the difference between torch.no_grad() and torch.inference_mode()?\n",
        "        # This was your previous homework, so you should know the answer already, though it is technical and subtle.\n",
        "        # Hint: the main difference is about creating tensor - one mode makes them impossible to use in the \"grad\" mode\n",
        "        # TODO: read this: https://docs.pytorch.org/docs/stable/notes/autograd.html#grad-modes\n",
        "        with torch.inference_mode():\n",
        "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
        "            output = torch.tensor(dummy_input) # so we will have a tensor to save results into\n",
        "\n",
        "            for layer in layers[:-1]:  # Exclude Flatten for now, though it doesn't matter really, Flatten does not change number of element\n",
        "                                       # (TODO: try it yourself); It is just so we can train accessing any part of the network we want\n",
        "                output = layer(output)\n",
        "            self.flatten_size = output.numel() # numel = number of elements in the tensor\n",
        "\n",
        "        # Add fully connected layers\n",
        "        layers.append(nn.Linear(self.flatten_size, architecture_config['fc_units']))\n",
        "        layers.append(nn.BatchNorm1d(architecture_config['fc_units']))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(architecture_config['dropout_fc']))\n",
        "        layers.append(nn.Linear(architecture_config['fc_units'], num_classes))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        # Loss function\n",
        "        # we are using class weights here to address class imbalance\n",
        "        # this makes sure, that misclassifying samples from minority classes\n",
        "        # is penalized more than misclassifying samples from majority classes\n",
        "\n",
        "        # The gradient steps for minority class samples are magnified, making the model learn to prioritize correctly classifying these samples.\n",
        "        # The batches themselves are still drawn from the imbalanced dataset distribution.\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "        # If we look at our code hard enough we will notice, that we are using BOTH\n",
        "        # the class weights and the weighted random sampler to address the class imbalance issue.\n",
        "        # Now, is it a good idea to use both of them at the same time?\n",
        "        # As always - it depends. It is, unfortunately, a nuanced topic that depends on the dataset and the problem.\n",
        "\n",
        "        # By using both we are effectively training on class-balanced batches (due to the Sampler) where the minority class samples' misclassification\n",
        "        # still receives a higher penalty (due to the weighted loss). This combination can be aggressive and might\n",
        "        # be useful for highly severe imbalance, but it could also lead to overfitting to the minority class if the weights are too extreme.\n",
        "\n",
        "\n",
        "        # In some cases, using both can lead to better performance, as the sampler ensures that\n",
        "        # the model sees a balanced representation of classes during training, while the loss function\n",
        "        # emphasizes the importance of minority classes.\n",
        "        # However, in other cases, it might lead to overcompensation for minority classes,\n",
        "        # causing the model to perform poorly on majority classes.\n",
        "        # It is often a good idea to experiment with both approaches separately and together\n",
        "        # to see what works best for your specific use case.\n",
        "\n",
        "        # TODO: experiment with using only one of these techniques at a time, and compare the results.\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        acc = (predicted == labels).float().mean()\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        acc = (predicted == labels).float().mean()\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1)\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"monitor\": \"val_loss\",\n",
        "            },\n",
        "        }\n"
      ],
      "metadata": {
        "id": "w8-KR2QSsIeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights for imbalanced dataset\n",
        "def compute_class_weights(dataset):\n",
        "    labels = [label for _, label in dataset.data]\n",
        "    class_counts = np.bincount(labels, minlength=9)\n",
        "    total_samples = len(labels)\n",
        "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
        "\n",
        "    # weights as tensor (to pass to the loss function)\n",
        "    return torch.tensor(class_weights, dtype=torch.float)"
      ],
      "metadata": {
        "id": "DIM7fR7ktfzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConfusionMatrixCallback(Callback):\n",
        "    def __init__(self, class_names):\n",
        "        self.class_names = class_names\n",
        "        self.val_labels = []\n",
        "        self.val_preds = []\n",
        "\n",
        "    def on_validation_epoch_start(self, trainer, pl_module):\n",
        "        self.val_labels = []\n",
        "        self.val_preds = []\n",
        "\n",
        "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
        "        images, labels = batch\n",
        "        with torch.no_grad():\n",
        "            pl_module.eval()\n",
        "            images = images.to(pl_module.device)\n",
        "            outputs = pl_module(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            self.val_labels.extend(labels.cpu().numpy())\n",
        "            self.val_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        cm = confusion_matrix(self.val_labels, self.val_preds)\n"
      ],
      "metadata": {
        "id": "4YD_bbBKtb9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, now we can analyze what has changed in this code:\n",
        "- The architecture is now defined by a configuration dictionary (architecture_config).\n",
        "- The convolutional blocks are created in a loop based on the configuration.\n",
        "- This allows us to easily modify the architecture by changing the configuration dictionary."
      ],
      "metadata": {
        "id": "gk-RKaL2sbTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try running our network first"
      ],
      "metadata": {
        "id": "JSvQeq2EtuD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data module\n",
        "batch_size = 64\n",
        "data_module = WasteDataModuleMulti(batch_size=batch_size)\n",
        "data_module.setup()\n",
        "\n",
        "# Compute class weights from training data\n",
        "class_weights = compute_class_weights(data_module.train_dataset)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Set class weights for weighted sampling\n",
        "data_module.class_weights = class_weights\n",
        "data_module.setup()  # Re-setup to compute sample weights"
      ],
      "metadata": {
        "id": "APPo2BCptsIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model with default architecture configuration\n",
        "# model = ParametricCNN()\n",
        "\n",
        "\n",
        "# Initialize model with custom architecture configuration\n",
        "architecture_config = {\n",
        "    'blocks': [\n",
        "        {'filters': 64, 'convs': 2},\n",
        "        {'filters': 128, 'convs': 2},\n",
        "        {'filters': 256, 'convs': 2},\n",
        "    ],\n",
        "    'dropout_conv': 0.25,\n",
        "    'fc_units': 512,\n",
        "    'dropout_fc': 0.5\n",
        "}\n",
        "\n",
        "model = ParametricCNN(architecture_config=architecture_config)"
      ],
      "metadata": {
        "id": "zvF9MACXt3hM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model summary\n",
        "summary(model, (3, 224, 224), device=\"cpu\")\n"
      ],
      "metadata": {
        "id": "JZGlCSrdt73k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or we can make it different"
      ],
      "metadata": {
        "id": "tjJhXXqPt-Up"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "architecture_config_alt_alternative = {\n",
        "    'blocks': [\n",
        "        {'filters': 64, 'convs': 3},\n",
        "        {'filters': 128, 'convs': 3},\n",
        "        {'filters': 256, 'convs': 3},\n",
        "        {'filters': 512, 'convs': 2},\n",
        "    ],\n",
        "    'dropout_conv': 0.3,\n",
        "    'fc_units': 1024,\n",
        "    'dropout_fc': 0.5\n",
        "}\n",
        "\n",
        "model = ParametricCNN(architecture_config=architecture_config_alt_alternative)"
      ],
      "metadata": {
        "id": "85I-cb65uA-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print model summary\n",
        "summary(model, (3, 224, 224), device=\"cpu\")\n"
      ],
      "metadata": {
        "id": "ItPm4-zcuD6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OK, this one \"looks fine\", let's try it"
      ],
      "metadata": {
        "id": "ugD9PrvDuSkG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup callbacks\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath='checkpoints/lightning_multiclass',\n",
        "    filename='best',\n",
        "    save_top_k=1,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_last=True\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=7,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "# Confusion matrix callback\n",
        "class_names = list(final_classes.keys())\n",
        "confusion_matrix_callback = ConfusionMatrixCallback(class_names)"
      ],
      "metadata": {
        "id": "UQch8-HsuWZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup trainer\n",
        "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
        "devices = list(range(torch.cuda.device_count())) if accelerator == 'gpu' else 1\n",
        "\n",
        "# low number, just to check everything works\n",
        "NUM_EPOCHS = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=NUM_EPOCHS,\n",
        "    callbacks=[checkpoint_callback, early_stopping_callback, confusion_matrix_callback],\n",
        "    accelerator=accelerator,\n",
        "    devices=devices\n",
        ")\n"
      ],
      "metadata": {
        "id": "GqWKjeGeudut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.fit(model, datamodule=data_module)"
      ],
      "metadata": {
        "id": "95d25wGVukF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "trainer.test(model, datamodule=data_module)"
      ],
      "metadata": {
        "id": "u84S0gzaul04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now try to experiment with different versions of this architecture.\n",
        "Right now we do not have any intuition about how the network should work, what it should have (elements, layers, blocks etc). We can only experiment to gain knowledge and understanding.\n",
        "\n",
        "The task is always the same - to create the best possible architecture. That means:\n",
        "\n",
        "\n",
        "*   Fastest possible\n",
        "*   Smallest size (memory footprint)\n",
        "*   Highest/lowest metric (usually accuracy)\n",
        "\n",
        "By changing our architecture we can try to reach balance between these points\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aSPNzb1wseM2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5H-LrgItwG3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK: Experiment manually with different configurations of the network."
      ],
      "metadata": {
        "id": "NsCnHMdTso5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TASK: Based on your knowledge implement a second architecture. This one will not be VGG-inspired, but based on AlexNET\n",
        "\n",
        "Implement modular versions of AlexNet based on this article:\n",
        "https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
        "\n",
        "WARNING: The original AlexNet worked on dual GPUs, so you might need to adjust the architecture.\n",
        "\n",
        "If you want (suggestion, not necessity) you can read some more details here:\n",
        "https://arxiv.org/abs/1404.5997\n",
        "\n",
        "**Experiment with different configurations**\n",
        "\n",
        "**Evaluate performance on the dataset**\n"
      ],
      "metadata": {
        "id": "EH8g4dAvvXB7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzP91V1FsIgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Manual vs automatic tuning\n",
        "\n",
        "After experimenting with architectures we know one thing for sure - this process can be tedious. Making small changes to architecture (like number of layers, filters etc) will impact how the network behaves. However, this is a slow and boring process, that needs supervision. Fortunately there are always better ways to do this.\n",
        "\n",
        "Therefore let us try to automate it.\n",
        "We can even use what we already have installed and tested in previous classes - CometML framework."
      ],
      "metadata": {
        "id": "LM0hck-VwOkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
        "from pytorch_lightning.loggers import CometLogger\n",
        "from torchsummary import summary\n",
        "import pytorch_lightning as pl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "import comet_ml\n",
        "\n",
        "# Set seed for reproducibility\n",
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "EcBqMduMw5yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data augmentations for training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ImageNet normalization\n",
        "])\n",
        "\n",
        "# Validation and test transforms\n",
        "val_test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "class WasteDataModuleMulti(LightningDataModule):\n",
        "    def __init__(self, root_dir='datasets/combined_waste_dataset',\n",
        "                 batch_size=32):\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.num_classes = 9  # organic, battery, glass, metal, paper, cardboard, plastic, textiles, trash\n",
        "        self.class_weights = None\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_dataset = CombinedWasteDatasetMulti(\n",
        "            root_dir=self.root_dir, split='train', transform=train_transform\n",
        "        )\n",
        "        self.val_dataset = CombinedWasteDatasetMulti(\n",
        "            root_dir=self.root_dir, split='val', transform=val_test_transform\n",
        "        )\n",
        "        self.test_dataset = CombinedWasteDatasetMulti(\n",
        "            root_dir=self.root_dir, split='test', transform=val_test_transform\n",
        "        )\n",
        "\n",
        "        self.num_workers = os.cpu_count() - 1\n",
        "\n",
        "\n",
        "        if self.class_weights is not None:\n",
        "            self.sample_weights = [self.class_weights[label].item() for _, label in self.train_dataset.data]\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        if hasattr(self, 'sample_weights'):\n",
        "\n",
        "            sampler = WeightedRandomSampler(self.sample_weights, len(self.train_dataset), replacement=True)\n",
        "\n",
        "            return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
        "                              sampler=sampler, num_workers=self.num_workers)\n",
        "        else:\n",
        "            return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
        "                              shuffle=True, num_workers=self.num_workers)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=False, num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=False, num_workers=self.num_workers)"
      ],
      "metadata": {
        "id": "mo50MARMw9Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ParametricCNN(LightningModule):\n",
        "    def __init__(self, num_classes=9, class_weights=None, architecture_config=None, learning_rate=1e-3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.num_classes = num_classes\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Default architecture config (our first, \"VGG-like\")\n",
        "        if architecture_config is None:\n",
        "            architecture_config = {\n",
        "                'blocks': [\n",
        "                    {'filters': 64, 'convs': 2},\n",
        "                    {'filters': 128, 'convs': 2},\n",
        "                    {'filters': 256, 'convs': 2},\n",
        "                ],\n",
        "                'dropout_conv': 0.25,\n",
        "                'fc_units': 512,\n",
        "                'dropout_fc': 0.5\n",
        "            }\n",
        "\n",
        "        self.architecture_config = architecture_config\n",
        "\n",
        "        # Build convolutional layers\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for block in architecture_config['blocks']:\n",
        "            for _ in range(block['convs']):\n",
        "                layers.append(nn.Conv2d(in_channels, block['filters'], kernel_size=3, padding=1))\n",
        "                layers.append(nn.BatchNorm2d(block['filters']))\n",
        "                layers.append(nn.ReLU())\n",
        "                in_channels = block['filters']\n",
        "            layers.append(nn.MaxPool2d(2, 2))\n",
        "            layers.append(nn.Dropout(architecture_config['dropout_conv']))\n",
        "\n",
        "        layers.append(nn.Flatten())\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            dummy_input = torch.zeros(1, 3, 224, 224)\n",
        "            output = torch.tensor(dummy_input) # so we will have a tensor to save results into\n",
        "\n",
        "            for layer in layers[:-1]:\n",
        "                output = layer(output)\n",
        "            self.flatten_size = output.numel() # numel = number of elements in the tensor\n",
        "\n",
        "        # Add fully connected layers\n",
        "        layers.append(nn.Linear(self.flatten_size, architecture_config['fc_units']))\n",
        "        layers.append(nn.BatchNorm1d(architecture_config['fc_units']))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(architecture_config['dropout_fc']))\n",
        "        layers.append(nn.Linear(architecture_config['fc_units'], num_classes))\n",
        "\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "        # Loss function\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        acc = (predicted == labels).float().mean()\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        images, labels = batch\n",
        "        outputs = self(images)\n",
        "        loss = self.loss_fn(outputs, labels)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        acc = (predicted == labels).float().mean()\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.1)\n",
        "        return {\n",
        "            \"optimizer\": optimizer,\n",
        "            \"lr_scheduler\": {\n",
        "                \"scheduler\": scheduler,\n",
        "                \"monitor\": \"val_loss\",\n",
        "            },\n",
        "        }\n"
      ],
      "metadata": {
        "id": "ncuCctCNw_5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights for imbalanced dataset\n",
        "def compute_class_weights(dataset):\n",
        "    labels = [label for _, label in dataset.data]\n",
        "    class_counts = np.bincount(labels, minlength=9)\n",
        "    total_samples = len(labels)\n",
        "    class_weights = total_samples / (len(class_counts) * class_counts)\n",
        "\n",
        "    # weights as tensor (to pass to the loss function)\n",
        "    return torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "\n",
        "class ConfusionMatrixCallback(Callback):\n",
        "    def __init__(self, class_names):\n",
        "        self.class_names = class_names\n",
        "        self.val_labels = []\n",
        "        self.val_preds = []\n",
        "\n",
        "    def on_validation_epoch_start(self, trainer, pl_module):\n",
        "        self.val_labels = []\n",
        "        self.val_preds = []\n",
        "\n",
        "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0):\n",
        "        images, labels = batch\n",
        "        with torch.no_grad():\n",
        "            pl_module.eval()\n",
        "            images = images.to(pl_module.device)\n",
        "            outputs = pl_module(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            self.val_labels.extend(labels.cpu().numpy())\n",
        "            self.val_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        cm = confusion_matrix(self.val_labels, self.val_preds)\n",
        "\n"
      ],
      "metadata": {
        "id": "gCbqOtVPxCuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data module\n",
        "batch_size = 64\n",
        "data_module = WasteDataModuleMulti(batch_size=batch_size)\n",
        "data_module.setup()\n",
        "\n",
        "# Compute class weights from training data\n",
        "class_weights = compute_class_weights(data_module.train_dataset)\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# Set class weights for weighted sampling\n",
        "data_module.class_weights = class_weights\n",
        "data_module.setup()  # Re-setup to compute sample weights\n"
      ],
      "metadata": {
        "id": "SEgrkQYPxFcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning Setup with CometML\n",
        "\n",
        "We use CometML's Optimizer for automated hyperparameter search.\n",
        "\n",
        "This allows us to search over architecture configurations efficiently.\n",
        "\n",
        "More details are available here (for example):\n",
        "\n",
        "https://www.comet.com/site/blog/hyperparameter-optimization-with-comet/\n"
      ],
      "metadata": {
        "id": "qy7jpuQoxGsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for testing purpuses let's set this to a very low value\n",
        "NUM_EPOCHS = 1\n"
      ],
      "metadata": {
        "id": "6_CB9kokxT7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create and train a model with given hyperparameters\n",
        "def train_model_with_params(params, data_module, class_weights, num_epochs=NUM_EPOCHS):\n",
        "    # Create architecture config from params\n",
        "    architecture_config = {\n",
        "        'blocks': [\n",
        "            {'filters': params['filters_block1'], 'convs': params['convs_block1']},\n",
        "            {'filters': params['filters_block2'], 'convs': params['convs_block2']},\n",
        "            {'filters': params['filters_block3'], 'convs': params['convs_block3']},\n",
        "        ],\n",
        "        'dropout_conv': params['dropout_conv'],\n",
        "        'fc_units': params['fc_units'],\n",
        "        'dropout_fc': params['dropout_fc']\n",
        "    }\n",
        "\n",
        "    # Initialize model\n",
        "    model = ParametricCNN(architecture_config=architecture_config, class_weights=class_weights, learning_rate=params['learning_rate'])\n",
        "\n",
        "    # Comet Logger for this experiment\n",
        "    comet_logger = CometLogger(\n",
        "            project=\"waste-classification-multiclass\",\n",
        "            name=\"lab4-hyperparam-tuning\")\n",
        "\n",
        "    # Callbacks\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        dirpath='checkpoints/lightning_multiclass',\n",
        "        filename='best-{epoch:02d}-{val_loss:.2f}',\n",
        "        save_top_k=1,\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_last=True\n",
        "    )\n",
        "\n",
        "    early_stopping_callback = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=7,\n",
        "        mode='min'\n",
        "    )\n",
        "\n",
        "    confusion_matrix_callback = ConfusionMatrixCallback(list(final_classes.keys()))\n",
        "\n",
        "    # Trainer\n",
        "    accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
        "    devices = [0]  # using a single GPU for hyperparameter tuning to avoid complications\n",
        "                   # TODO: IF you have access to multiple GPUs, you can try and see what happens, with the CURRENT code configuration\n",
        "                   # and distribution strategy set in Pytorch Lightning Trainer.\n",
        "\n",
        "    trainer = Trainer(\n",
        "        max_epochs=num_epochs,\n",
        "        callbacks=[checkpoint_callback, early_stopping_callback, confusion_matrix_callback],\n",
        "        accelerator=accelerator,\n",
        "        devices=devices,\n",
        "        logger=comet_logger\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    trainer.fit(model, datamodule=data_module)\n",
        "    # this will log \"train_loss\", \"val_loss\" and \"val_acc\"  metrics\n",
        "    return trainer.callback_metrics['val_loss'].item()\n",
        "\n",
        "\n",
        "    # This part is commented out for a reason - more on that below\n",
        "    # # Test the model\n",
        "    # trainer.test(model, datamodule=data_module)\n",
        "    # # this will log \"test_loss\" and \"test_acc\" logged metrics\n",
        "\n",
        "    # # Return the best validation loss for optimization\n",
        "    # return trainer.callback_metrics['test_loss'].item()\n"
      ],
      "metadata": {
        "id": "CfpoiI-BxZbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now must as ourselves a very important questions - which is correct here? Can we use validation loss or test loss for hyperparameter tuning?\n",
        "Or, to be more precise, are we ALLOWED to use test loss for hyperparameter tuning?\n",
        "\n",
        "**TODO: Think about this question carefully and answer yourselves**\n",
        "\n",
        "I will give you my point of view on this question:\n",
        "\n",
        "In general, you should NOT use test loss for hyperparameter tuning.\n",
        "The test set is supposed to be a completely unseen dataset that you only use at the very end of your model development process to get an unbiased estimate of your model's performance.\n",
        "\n",
        "If you use the test set for hyperparameter tuning, you are effectively \"peeking\" at the test data, using the test set to guide your model selection.\n",
        "\n",
        "This can lead to overfitting to the test set and an overly optimistic estimate of your model's performance, not reflective of its true generalization ability.\n",
        "\n",
        "Therefore, it is best practice to use a separate validation set for hyperparameter tuning, and only use the test set once you have finalized your model.\n",
        "\n",
        "If you, however, have a different oppinion on this matter, I would be very interested to hear it. Never to argue/mock, but to discuss what it really means to have a \"good\" model evaluation strategy, as this is one of the most important parts of creating and later deploting a proper model.\n"
      ],
      "metadata": {
        "id": "RRCXHvaPxhvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be using CometML Optimizer for Hyperparameter Tuning\n",
        "Main references:\n",
        "\n",
        "**TODO: READ THESE LINKS THOROUGHLY**\n",
        "\n",
        "using Comet Optimizer is an advanced topic, and to use it properly it is ALWAYS advised to read the documentation.\n",
        "\n",
        "Truth be told - even with the documentation it can be tricky to set up properly.\n",
        "\n",
        "But once set up, it can save you a lot of time and effort in hyperparameter tuning.\n",
        "\n",
        "Digresion: Any hyperparameter tuning framework is \"complicated\" to set up properly.\n",
        "Because hyperparameter tuning is inherently complicated.\n",
        "\n",
        "You need to make sure that your training code is properly modularized,\n",
        "that hyperparameters are passed correctly, that logging is set up properly, etc.\n",
        "\n",
        "So don't be discouraged if it takes some time to get it right.\n",
        "Once you have a working setup, you can reuse it for future projects.\n",
        "\n",
        "\n",
        "https://www.comet.com/docs/v2/api-and-sdk/python-sdk/reference/Optimizer/\n",
        "\n",
        "https://www.comet.com/docs/v2/guides/optimizer/quickstart/\n"
      ],
      "metadata": {
        "id": "oOUYorMEyE9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Source: https://www.comet.com/docs/v2/guides/optimizer/quickstart/*\n",
        "\n",
        "Before you begin optimization, you need to choose:\n",
        "\n",
        "    * The hyperparameters to tune.\n",
        "    * The search space for each hyperparameter to tune.\n",
        "    * The search algorithm (one of grid search, random search, and Bayesian optimization).\n",
        "\n",
        "Additionally, make sure to refactor your existing model training code so that hyperparameters are defined as parametrized variables."
      ],
      "metadata": {
        "id": "dVnRjxyGyHiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define hyperparameter search space\n",
        "# CometML Optimizer uses this to suggest parameters\n",
        "\n",
        "# SOOOOOOOOO MANY parameters to tune here...\n",
        "# is it too much maybe? Will we even be able to train anything in reasonable time?\n",
        "\n",
        "param_space = {\n",
        "    \"filters_block1\": {\"type\": \"discrete\", \"values\": [32, 64, 128]}, # DO NOT USE INTEGER, where there is so much difference between values\n",
        "    \"convs_block1\": {\"type\": \"integer\", \"min\": 1, \"max\": 3}, # here is ok\n",
        "    \"filters_block2\": {\"type\": \"discrete\", \"values\": [64, 128, 256]},\n",
        "    \"convs_block2\": {\"type\": \"integer\", \"min\": 1, \"max\": 3},\n",
        "    \"filters_block3\": {\"type\": \"discrete\", \"values\": [128, 256, 512]},\n",
        "    \"convs_block3\": {\"type\": \"integer\", \"min\": 1, \"max\": 3},\n",
        "    \"dropout_conv\": {\"type\": \"float\", \"min\": 0.1, \"max\": 0.5},\n",
        "    \"fc_units\": {\"type\": \"discrete\", \"values\": [256, 512, 1024]},\n",
        "    \"dropout_fc\": {\"type\": \"float\", \"min\": 0.3, \"max\": 0.7}, # TODO: WHY NOT DISCRETE? or maybe it should be discrete????????\n",
        "    \"learning_rate\": {\"type\": \"float\", \"scalingType\": \"loguniform\", \"min\": 1e-4, \"max\": 1e-2} # TODO: log uniform?? what is that??? Try to read about this parameter\n",
        "                                                                                              # other options are: ['linear', 'uniform', 'loguniform', 'normal', 'lognormal']\n",
        "}\n"
      ],
      "metadata": {
        "id": "IomNoBNayktG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: look at the parameters above.\n",
        "\n",
        "Do we really need to test all of them, especially at once? If not, maybe you can trim this parameters space?\n"
      ],
      "metadata": {
        "id": "vFSNXCeJypIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Strategy 1: Random Search (Active)\n",
        "\n",
        "Random search samples parameters randomly from the space.\n",
        "\n",
        "It's simple, effective, and doesn't assume parameter relationships.\n",
        "\n",
        "Random search is, as the name implies, randomly selecting combinations of hyperparameter values to try out.\n",
        "\n",
        "It can be good, if we do not know much about the hyperparameter space,\n",
        "or if we suspect that only a few hyperparameters have a significant impact on performance.\n",
        "\n",
        "As with a lot of things in machine learning, doing something randomly can sometimes outperform more \"intelligent\" approaches.\n",
        "\n",
        "Though Grid is still usually better than pure random guessing."
      ],
      "metadata": {
        "id": "qFGZKDuzy7O-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Source: https://www.comet.com/site/blog/hyperparameter-optimization-with-comet/*\n",
        "\n",
        "Random search offers slightly more flexibility than grid search.\n",
        "Instead of exhaustively iterating through all possible combinations like in the grid search algorithm,\n",
        "random search selects combinations at random from the possible parameter\n",
        "values until the run is explicitly stopped or the max combinations are met.\n",
        "\n",
        "Similar to grid search, the random algorithm does not use past experiments to inform future experiments,\n",
        "but when only a small number of hyperparameters have an effect on the final model performance,\n",
        "the random search can outperform grid search."
      ],
      "metadata": {
        "id": "HEnNqGJYzE7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.comet.com/docs/v2/guides/optimizer/configure-optimizer/\n",
        "config_dict = {\n",
        "    \"algorithm\": \"random\",\n",
        "    \"spec\": {\n",
        "        \"metric\": \"accuracy\",\n",
        "        \"maxCombo\": 5, # VERY important parameter - make sure you know what it does\n",
        "        \"gridSize\": 5,\n",
        "        \"minSampleSize\": 150,\n",
        "    },\n",
        "    \"parameters\": param_space,\n",
        "    \"name\": \"My Random Search\",\n",
        "    \"trials\": 1, # read the docs to understand what this does - might be misleading at first\n",
        "}"
      ],
      "metadata": {
        "id": "wDNf8EPCzKm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_random = comet_ml.Optimizer(config=config_dict)"
      ],
      "metadata": {
        "id": "mvVWIBSCzO27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is our actual hyperparameter tuning loop\n",
        "As you can see we are calling our training function with different parameters suggested by the optimizer\n",
        "This makes it very easy to integrate hyperparameter tuning into existing training code\n",
        "\n",
        "This is mostly the same thing as calling it manually, but we do not have to implement the tuning \"strategy\" ourselves\n",
        "or, properly called, the \"search algorithm\".\n",
        "This is the main point of all the frameworks for hyperparameter tuning - to avoid reinventing the wheel\n",
        "But you could easily do this yourself if you wanted to.\n",
        "\n",
        "\n",
        "What we are doing is called \"black-box optimization\", because we do not have to know anything about the function we are optimizing\n",
        "we just provide inputs (hyperparameters) and get outputs (validation loss)"
      ],
      "metadata": {
        "id": "uBc14SMAzTmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization\n",
        "for experiment in opt_random.get_experiments():\n",
        "    params = experiment.params\n",
        "    val_loss = train_model_with_params(params, data_module, class_weights, num_epochs=NUM_EPOCHS)  # Short epochs for demo\n",
        "    experiment.log_metric(\"val_loss\", val_loss)"
      ],
      "metadata": {
        "id": "bb1xA2JQzWwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Strategy 2: Bayesian Optimization (Active Alternative)\n",
        "Bayesian optimization uses probabilistic models to suggest promising parameters.\n",
        "\n",
        "It's more efficient than random search for continuous spaces.\n",
        "It is an \"intelligent\" search strategy that builds a model of the hyperparameter space and uses it to select the most promising hyperparameters to evaluate next.\n",
        "\n",
        "This approach can be more efficient than random search, especially when the hyperparameter space is large and continuous, as it focuses on areas likely to yield better performance.\n"
      ],
      "metadata": {
        "id": "Cmc3pogozdQD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Source: https://www.comet.com/site/blog/hyperparameter-optimization-with-comet/*\n",
        "\n",
        "Comet documentation states the Bayes algorithm may be the best choice for most of your Optimizer uses.\n",
        "\n",
        "    Bayesian optimization has been shown to obtain better results in fewer evaluations compared to grid search and random search,\n",
        "    due to the ability to reason about the quality of experiments before they are run.  Wikipedia\n",
        "\n",
        "Bayes optimization works by iteratively evaluating a promising hyperparameter configuration\n",
        "based on the current model, then updating it. The main aim of the technique is to gather observations\n",
        "that reveal as much information as possible about the location of the optimum."
      ],
      "metadata": {
        "id": "2xzbGHErzm5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_dict = {\n",
        "    \"algorithm\": \"bayes\",\n",
        "    \"spec\": {\n",
        "        \"objective\": \"maximize\",\n",
        "        \"metric\": \"accuracy\",\n",
        "        \"maxCombo\": 5, # VERY important parameter - make sure you know what it does\n",
        "        \"retryLimit\": 10,\n",
        "        \"retryAssignLimit\": 10,\n",
        "    },\n",
        "    \"parameters\": param_space,\n",
        "    \"name\": \"My Bayesian Search\",\n",
        "    \"trials\": 1,\n",
        "}\n",
        "\n",
        "opt_bayes = comet_ml.Optimizer(config=config_dict)"
      ],
      "metadata": {
        "id": "IJZOjQ2NzqM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the optimization\n",
        "for experiment in opt_bayes.get_experiments():\n",
        "    params = experiment.params\n",
        "    val_loss = train_model_with_params(params, data_module, class_weights, num_epochs=NUM_EPOCHS)\n",
        "    experiment.log_metric(\"val_loss\", val_loss)"
      ],
      "metadata": {
        "id": "8z6AVQuOzsh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Strategies Available in CometML:\n",
        "- Grid Search: Exhaustive search over specified combinations.\n",
        "  Set algorithm=\"grid\" and provide a list of values for each parameter.\n",
        "\n",
        "**TODO: Implement grid search yourself**\n",
        "\n",
        "It is more widely used than random search, but not as much as Bayesian optimization.\n",
        "Pretty please read the documentation to understand how to set up the parameters dictionary for grid search.\n",
        "Not all the parameters exist for every search strategy!\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GP9lsigPzvzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**TODO: Is this the only way to do hyperparameter tuning with PyTorch Lightning?**\n",
        "\n",
        "Of course not. There are many other libraries and frameworks available for hyperparameter tuning, such as Optuna, Ray Tune, etc. Each has its own strengths and weaknesses.\n",
        "\n",
        "Even PyTorch Lightning itself has built-in support for very simple tuning:\n",
        "\n",
        "https://lightning.ai/docs/pytorch/stable/api/lightning.pytorch.tuner.tuning.Tuner.html#lightning.pytorch.tuner.tuning.Tuner\n",
        "\n",
        "CometML is just one option that integrates well with PyTorch Lightning and provides a user-friendly interface for tracking experiments and visualizing results.\n",
        "Depending on your specific needs and preferences, you may find other tools more suitable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6cho_ySpz1bs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Homework Task:\n",
        "based on what you have learned in this lab, implement hyperparameter tuning using Optuna\n",
        "\n",
        "You will find more information about Optuna here:\n",
        "\n",
        "https://optuna.org/\n",
        "\n",
        "\n",
        "and here:\n",
        "\n",
        "https://pytorch-lightning.readthedocs.io/en/stable/extensions/optuna.html\n",
        "\n",
        "\n",
        "and also here:\n",
        "\n",
        "https://optuna-integration.readthedocs.io/en/stable/index.html"
      ],
      "metadata": {
        "id": "gDaO-Mi5z_yP"
      }
    }
  ]
}